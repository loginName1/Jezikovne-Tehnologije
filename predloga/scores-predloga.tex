%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,nonacm]{acmart}
%% NOTE that a single column version may be required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2022}
\acmYear{2022}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[SCORES'22]{Student Computing Research Symposium}{October 6,
2022}{Ljubljana, Slovenia}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

\newcommand{\scores}{\textsc{SCORES}}
\renewcommand{\keywordsname}{Ključne besede}
\renewcommand{\acksname}{Zahvala}

\usepackage[slovene]{babel}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{booktabs}
\usepackage[linesnumbered, boxed, resetcount]{algorithm2e}
\SetAlgorithmName{Algoritem}{Algoritem}

%%
%% If you need any other LaTeX packages, add them here
%%

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Uporaba jezikovnih tehnologij za identifikacijo elektronskih prevar}


%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Adam Baša}
%\authornote{Vsi trije avtorji so prispevali enakovreden dele\v{z}.}
\email{adam.basa@student.um.si}
\affiliation{%
    \institution{Faculty of Electrical \\Engineering and Computer Science,\\
    University of Maribor\\Koroška cesta 46}
    \city{SI-2000 Maribor}
    \country{Slovenia}
}

\author{Jan Benko}
%\authornotemark[1]
\email{jan.benko1@student.um.si}
\affiliation{%
    \institution{Faculty of Electrical \\Engineering and Computer Science,\\
    University of Maribor\\Koroška cesta 46}
    \city{SI-2000 Maribor}
    \country{Slovenia}
}

\author{Tim Vehovar}
%\authornotemark[1]
\email{tim.vehovar@student.um.si}
\affiliation{%
    \institution{Faculty of Electrical \\Engineering and Computer Science,\\
    University of Maribor\\Koroška cesta 46}
    \city{SI-2000 Maribor}
    \country{Slovenia}
}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
   V modernem svetu se pojavlja čedalje več prevarantov, ki s pomočjo nepristnih spletnih strani kradejo podatke svojih žrtev in s temi podaki kradejo denar. Tehnološko bolj pismeni take prevare lahko zelo hitro identificirajo in jih ignorirajo, vendar pa niso vse žrtve take. Zato smo se odločili raziskati kako lahko z uporabo analize naravnega jezika ugotovimo ali je prejeto elektronsko sporočilo pristno ali prevara. To bomo storili s pomočjo jezikovnih modelov in nevralnih mrež. 
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{analiza naravnega jezika, elektronske prevare, nevralne mreže, jezikovni modeli}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Uvod}

S hitrim razvojem računalniških tehnologij je prišel tudi hiter razvoj interneta, ki nam danes omogoča hitro in preprosto komunikacijo, predvajanje video vsebin, kupovanje raznih produktov v spletnih trgovinah, naročevanje hrane na dom in še veliko več. Vendar pa s takšno povezanostjo pridejo tudi negativne posledice velikokrat javno dostopnih podatkov. Nekateri posamezniki so ugotovili, da lahko s temi podatki pridejo tudi do zaslužka. Ne glede na to, kako previdni smo s svojimi podatki, se ti lahko vedno pojavijo v rokah novodobnih roparjev. Že elektronski naslov je dovolj, da dobimo vprašljivo sporočilo od naše banke ali dostavljalnega podjetja glede izgubljenega paketa, ki od nas zahteva prijavo na njihovi spletni strani, katere spletni naslov je prikladno dodan v sporočilu. Ti prevaranti velikorat izvajajo svoje prevare izven domovine njihovih žrtev, saj je to varneje za njih. Zato so sporočila v imenu uradnih ustanov prevedena iz njihovega maternega jezika. Tu pa se lahko pojavijo razne slovnične napake, ki jih nekatere žrtve spregledajo, ali pa niso niti pozorne na pravopis sporočila. Take napake velikokrat privedejo do izgube denarja ali česa hujšega. Da bi preprečili take napade, smo se odločili, da bomo poskusili izvesti analizo naravnega jezika sporočila in ugotoviti, ali je sporočilo pristno ali ne.

\section{Pregled obstoječe literature}
Podobno tematiko je že nekaj raziskovalcev objavilo v raznih člankih, zato bomo pregledali nekaj virov, ki nam bodo pomagali pri pisanju lastnega članka.

Pri analizi potencialnih phishing \cite{rekouche2011early} strani je veliko različnih elementov, ki jih je potrebno pregledati in nato določiti, ali gre za zlonamerno stran. To lahko storimo s pomočjo umetnih nevralnih mrež \cite{Zou2009} in z globokim učenjem \cite{lecun2015deep}. Avtorji članka \cite{HAYNES2021127} so sprva želeli analizirati elektronska sporočila na mobilnih napravah s pomočjo globokih nevralnih mrež, vendar so rezultati bili podpovprečni. Zato so se odločili poskusiti implementirati analizo elektronskega naslova s pomočjo transformatorskih jezikovnih modelov \cite{9222960}. Avtorji so tako postavili svojo hipotezo, da bi taki modeli lahko povezali vsebino elektronskega naslova z vsebino strani in tako določili, ali je stran pristna ali ne.  Za dokaz svoje hipoteze so uporabili že obstoječa transformatorska modela, in sicer BERT \cite{devlin2018bert} in ELECTRA \cite{clark2020electra}. Izkazalo se je celo, da je predhodno učen javno dostopen model dosegel boljši rezultat kot model, ki je bil učen s pomočjo po meri ustvarjenega slovarja. Prednosti takega pristopa so, da je čas učenja zalo kratek, ni potrebno obdelati podatke pred analizo, je varneje, ker ni potrebno obiskati spletnih strani, ki so lahko nevarne in pa jih lahko uporabimo tudi na mobilnih napravah. 

Za analizo elektronske pošte lahko pregledamo besedilo sporočila. Pri pregledu lahko preverjamo, če obstajajo vzorci, ki so značilni za lažna sporočila. V tem primeru bi govorili o sentimentu sporočila. Točno to so se odločili storiti avtorji v članku \cite{stone2007ebids}. Natačneje pa so preverili, če besedilo vsebuje koncepte manipulacije in jih poskusili pravilno določiti. To so storili z lastnim OntoSem projektom, ki so ga razvili v enem izmed laboratorijev Univerze v Marylandu. Čeprav izbran projekt ni premagal ostalih že obstoječih sistemov, je vseeno dosegel kar 75-\% stopnjo odkrivanja manipulativnih elektronskih sporočil s samo štirimi navodili detekcije. Uporabljen sistem bi lahko še izboljšali z uporabo več pravil in mogoče s tem izboljšali stopnjo odkrivanja. 

V primeru dobro izdelanih prevar je lahko težko klasificirati sporočilo po le eni značilnosti, zato lahko analiziramo vse komponente skupaj. Pregledamo lahko sporočilo, meta podatke in druge dele prevare. Avtorji dela \cite{mittal2022phishing} so to dosegli s posebnim ogrodjem, ki je sestavljeno iz več različnih modelov. Posamezni model lahko analizira določen del elektronskega sporočila in s pomočjo nevralne mreže določi, ali gre za pristno ali lažno komponento. To ogrodje se imenuje DARTH. Sestavljeno je iz več različnih nevralnih mrež, ki delujejo z različnimi modeli. Ko ogrodje razdeli elektronsko sporočilo na posamične dele, vsaka nevralna mreža oceni svoj del in pošlje rezultat analize v končno nevralno mrežo, ki deluje na principu ansambelskega učenja \cite{682375}. Na koncu je avtorjem uspelo doseči kar 98,99-\% stopnjo odkrivanja prevar in lažnih sporočil s tem ogrodjem. Učno in testno množico pa so ustvarili s pomočjo raznih virov, med drugim tudi s \emph{phishtank.com}.

\section{Pridobivanje podatkov}
\subsection{Model BERT}
Za obdelavo podatkov smo uporabili odprtokodni jezikovni model BERT (Bidirectional Encoder Representations from Transformers), ki ga je leta 2018 razvil Google. Temelji na arhitekturi Transformer, ki omogoča učinkovito obdelavo naravnega jezika. BERT omogoča branje v obe smeri (do BERT modela so jezikovni modeli obdelovali kontekst ali od leve proti desni ali obratno). To pomeni, da BERT razume besede v njihovem celotnem kontekstu, kar ga naredi zelo učinkovitega pri številnih nalogah, kot so razumevanje jezika, strojno prevajanje, odgovarjanje na vprašanja, analiza sentimenta in drugi jezikovni izzivi. Lahko prepozna, ali imata dva konteksta kakšno povezavo med sabo in logiko. BERT deluje na podlagi globokega učenja. Arhitektura BERT uporablja Transformerje, ki so vrsta nevronskih mrež, zgrajenih iz več plasti. Transformerji so znani po svoji sposobnosti učinkovite obdelave sekvenc podatkov, kot so nizi besed v jezikovnih nalogah. Transformer pregleda povezave med podano besedo in besedami okoli nje v povedi, kar omogoča boljše razumevanje konteksta. Za pravilno delovanje in učenje potrebuje model BERT učno in testno množico podatkov.

\subsection{Priprava podatkov}
Za naš eksperiment smo uporabili BERT base model \cite{turc2019}. BERT base model se nanaša na osnovno različico BERT modela, ki ima manjše število plasti in parametrov v primerjavi z drugimi variantami, kot je na primer BERT large model. BERT base model običajno vsebuje okoli 12 plasti Transformerjev. To lahko omeji zmogljivost modela pri reševanju kompleksnejših nalog, vendar je hkrati tudi manj zahteven za uporabo zaradi manjšega števila parametrov.
Za pridobivanje podatkov smo potrebovali URL povezave phishing strani in verodostojne strani. URL povezave phishing strani smo pridobili iz PhishTank, verodostojne pa s strani Common Crawl.
Pridobivanje podatkov s strani PhishTank je bilo malo težje za izvesti. Python koda za pridobivanje podatkov se najprej poveže na Phistank stran. Nato določi URL, ki bo vseboval povezave do sumljivih URL-jev in povezane URL-je phishing strani. Za vsako sumljivo spletno stran preveri, ali je ta sploh dosegljiva. Nato izvleče ID in URL phishing strani iz HTML vsebine, ki je pridobljena iz določene strani PhishTank-a. Sledi glavna metoda 'scrape', ki izvaja celoten postopek pridobivanja sumljivih URL-jev. Obišče določeno število strani PhishTank-a (določeno s page\_range), izvleče ID-je sumljivih URL-jev in z njimi povezane phishing strani ter jih shrani v slovar phish\_url\_dict. Pridobljeni podatki so nato shranjeni v CSV datoteko. Vsak zapis v CSV vsebuje ID sumljivega URL-ja in povezavo do phishing strani.
Pridobivanje podatkov s strani Common Crawl je bilo bolj enostavno za izvesti. Podatke smo pridobili s pomočjo Python funkcije 'extract\_urls\_from\_cdx\_files'. Funkcija najprej odpre indeksirano datoteko CDX in nato prebere vrstice ter razdeli te na dele glede na presledke. Glavni del, ki nas zanima, je tisti, ki je na indeksu 3 v delih. To je URL, ki ga želimo izvleči. Vsakih 1000 vrstic se URL doda v seznam, dokler ni dosežena omejitev.

\begin{lstlisting}[language=Python, breaklines=false, xrightmargin=0.1\textwidth, basicstyle=\footnotesize]
# EXTRACT COMMON CRAWL DATA
def extract_urls_from_cdx_file(file_path, limit=100):
    urls = []
    line_count = 0
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.rstrip()  # Remove newline character
            if not line:
                continue
            try:
                parts = line.split(' ')
	     # Extract the URL and remove the quotation 
	     #marks and trailing comma
                url = parts[3][1:-2]  
                line_count += 1
                if line_count % 1000 == 0:
                    urls.append(url)
                if len(urls) >= limit:
                    break
            except Exception as e:
                print(f'Error processing line: {line}. Error: {e}')
                continue
    return urls
\end{lstlisting}

Ko smo imeli podatke, smo jih mogli urediti in dati v skupno datoteko. Obdelani podatki so vsebovali ID, številko, ki je opredelila, ali je stran verodostojna ali ne. Sledila je naključna črka (uporabili smo črko a), brez katere model ni deloval. Nato je sledil URL. 

\section{Priprava okolja}
Za učenje in klasifikacijo URL naslovov, rabimo nekatera orodja. Osnovni model BERT deluje na nekaterih starejših verzija raznih knjižnic ali jezikov. Ker gre za program napisan v Pythonu, je potrebno naložiti nekaj paketov. Za začetek rabimo pravilno verzijo jezika. Glede na uporabljene knjižnice v samem projektu smo uporabili Python 3.7.9. Čeprav sam model ne zahteva te različice jezika, jo pa zahtevajo knjižnice v projektu. Za konverzijo žetonov v učljivo množico podatkov uporabimo knjižnico Tensorflow. Ker gre za zastarele različice knjižnic in jezika smo vse skupaj izvedli v virtualnem okolju Python.

\section{Učenje}
Po pridobitvi podatkov, smo izvedli učenje. Učenje poteka s pomočjo TensorFlow knjižnice

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliografija}

\end{document}
